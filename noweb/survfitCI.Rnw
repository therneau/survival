\subsection{Competing risks}
\newcommand{\Twid}{\mbox{\(\tt\sim\)}}
The competing risks routine is very general, allowing subjects
to enter or exit states multiple times.
Early on I used the label \emph{current prevalence} estimate, 
since it estimates what fraction of the subjects are in any
given state across time.  
However the word ``prevalence'' is likely to generate confusion whenever
death is one of the states, due to its historic use as the fraction of
living subjects who have a particular condition.
We will use the phrase \emph{probability in state} or simply $P$
from this point forward.

The easiest way to understand the estimate is to consider first the
case of no censoring.  
In that setting the estimate of $F_k(t) = 1-S_k(t)$ for all states
is obtained from a simple table of the current state at time $t$
of the subjects, divided by $n$, the original
sample size.
When there is censoring the conceptually simple way to extend this
is via the redistribute-to-the-right algorithm, which allocates the
case weight for a censored subject evenly to all the others in the
same state at the time of censoring.  

The literature refers to these as ``cumulative incidence'' curves,
which is confusing since P(state) is not the integral of incidence,
but the routine name survfitCI endures.
The cannonical call is one of
\begin{verbatim}
  fit <- survfit(Surv(time, status) ~ sex, data=mine)
  fit <- survfit(Surv(time1, time2, status) ~ sex, data=mine)

\end{verbatim}
where \code{status} is a factor variable.
Optionally, there can be an id statement
or cluster term to indicate a data set with multiple transitions per subject.
For multi-state survival the status variable has multiple levels,
the first of which by default is censoring, and others indicating
the type of transition that occured.
The result will be a matrix of survival curves, one for each event type.
If no initial state is specified then subjects are assumed
to start in a "null" state, which gets listed last and by default will
not be printed or plotted.  (But it is present, with a name of `');
  
The first part of the code is standard, parsing out options and
checking the data.
<<survfitCI>>= 
<<survfitCI-compute>>
survfitCI <- function(X, Y, weights, id, cluster, robust, istate,
                      stype=1, ctype=1,
                      se.fit=TRUE,
                      conf.int= .95,
                      conf.type=c('log',  'log-log',  'plain', 'none', 
                                  'logit', "arcsin"),
                      conf.lower=c('usual', 'peto', 'modified'),
                      influence = FALSE, start.time, p0, type){

    if (!missing(type)) {
        if (!missing(ctype) || !missing(stype))
            stop("cannot have both an old-style 'type' argument and the stype/ctype arguments that replaced it")
        if (!is.character(type)) stop("type argument must be character")
        # older style argument is allowed
        temp <- charmatch(type, c("kaplan-meier", "fleming-harrington", "fh2"))
        if (is.na(temp)) stop("invalid value for 'type'")
        type <- c(1,3,4)[temp]
    }
    else {
        if (!(ctype %in% 1:2)) stop("ctype must be 1 or 2")
        if (!(stype %in% 1:2)) stop("stype must be 1 or 2")
        type <- as.integer(2*stype + ctype  -2)
    }
    if (type != 1) warning("only stype=1, ctype=1 currently implimented for multi-state data")

    conf.type <- match.arg(conf.type)
    conf.lower<- match.arg(conf.lower)
    if (conf.lower != "usual") 
        warning("conf.lower is ignored for multi-state data")
    if (is.logical(conf.int)) {
        # A common error is for users to use "conf.int = FALSE"
        #  it's illegal per documentation, but be kind
        if (!conf.int) conf.type <- "none"
        conf.int <- .95
    }

 
    if (is.logical(influence)) {
        # TRUE/FALSE is treated as all or nothing
        if (!influence) influence <- 0L
        else influence <- 3L
    }
    else if (!is.numeric(influence))
        stop("influence argument must be numeric or logical")
    if (!(influence %in% 0:3)) stop("influence argument must be 0, 1, 2, or 3")
    else influence <- as.integer(influence)
 
    if (!se.fit) {
        # if the user asked for no standard error, skip any robust computation
        ncluster <- 0L
        influence <- 0L
    }

    type <- attr(Y, "type")
    # This line should be unreachable, unless they call "surfitCI" directly
    if (type !='mright' && type!='mcounting')
         stop(paste("multi-state computation doesn't support \"", type,
                          "\" survival data", sep=''))
    
    # If there is a start.time directive, start by removing any prior events
    if (!missing(start.time)) {
        if (!is.numeric(start.time) || length(start.time) !=1
            || !is.finite(start.time))
            stop("start.time must be a single numeric value")
        toss <- which(Y[,ncol(Y)-1] <= start.time)
        if (length(toss)) {
            n <- nrow(Y)
            if (length(toss)==n) stop("start.time has removed all observations")
            Y <- Y[-toss,,drop=FALSE]
            X <- X[-toss]
            weights <- weights[-toss]
            if (length(id) ==n) id <- id[-toss]
            if (!missing(istate) && length(istate)==n) istate <- istate[-toss]
            }
    }
    n <- nrow(Y)
    status <- Y[,ncol(Y)]
    ncurve <- length(levels(X))
    
    # The user can call with cluster, id, robust or any combination.
    # If only id, treat it as the cluster too
    if (missing(robust) || length(robust)==0) robust <- TRUE
    if (!robust) stop("multi-state survfit supports only a robust variance")

    has.cluster <-  !(missing(cluster) || length(cluster)==0) 
    has.id <-       !(missing(id) || length(id)==0)
    if (has.id) id <- as.factor(id)
    else  {
        if (ncol(Y) ==3) stop("an id statement is required for start,stop data")
        id <- 1:n  # older default, which could lead to invalid curves
    }
    if (influence && !(has.cluster || has.id)) {
        cluster <- seq(along=X)
        has.cluster <- TRUE
    }

    if (has.cluster) {
        if (is.factor(cluster)) {
            clname <- levels(cluster)
            cluster <- as.integer(cluster)
        } else {
            clname  <- sort(unique(cluster))
            cluster <- match(cluster, clname)
        }
        ncluster <- length(clname)
    } else {
        if (has.id) {
            # treat the id as both identifier and clustering
            clname <- levels(id)
            cluster <- as.integer(id)
            ncluster <- length(clname)
        }
        else {
            ncluster <- 0  # has neither
            clname <- NULL
        }
    }

    if (missing(istate) || is.null(istate))
        mcheck <- survcheck2(Y, id)  
    else mcheck <- survcheck2(Y, id, istate)
    if (any(mcheck$flag > 0)) stop("one or more flags are >0 in survcheck")
    states <- mcheck$states
    istate <- mcheck$istate
    nstate <- length(states) 
    smap <- c(0, match(attr(Y, "states"), states))
    Y[,ncol(Y)] <- smap[Y[,ncol(Y)] +1]      # new states may be a superset
    status <- Y[,ncol(Y)]

    if (mcheck$flag["overlap"] > 0)
        stop("a subject has overlapping time intervals")
#    if (mcheck$flag["gap"] > 0 || mcheck$flag["jump"] > 0)
#        warning("subject(s) with time gaps, results may be questionable")

    # The states of the status variable are the first columns in the output
    #  any extra initial states are later in the list. 
    # Now that we know the names, verify that p0 is correct (if present)
    if (!missing(p0) && !is.null(p0)) {
        if (length(p0) != nstate) stop("wrong length for p0")
        if (!is.numeric(p0) || abs(1-sum(p0)) > sqrt(.Machine$double.eps))
            stop("p0 must be a numeric vector that adds to 1")
    } else p0 <- NULL
@
 
The status vector will have values of 0 for censored.
<<survfitCI>>=
    curves <- vector("list", ncurve)
    names(curves) <- levels(X)
                            
    if (ncol(Y)==2) {  # 1 transition per subject
        # dummy entry time that is < any event time
        t0 <- min(0, Y[,1])
        entry <- rep(t0-1, nrow(Y))
        for (i in levels(X)) {
            indx <- which(X==i)
            curves[[i]] <- docurve2(entry[indx], Y[indx,1], status[indx], 
                                    istate[indx], weights[indx], 
                                    states, 
                                    id[indx], se.fit, influence, p0)
         }
    }
    else {
        <<survfitCI-extracens>>
        <<survfitCI-startstop>>
    }

    <<survfitCI-finish>>
}
@         
        
In the multi-state case we can calculate the current P(state)
vector $p(t)$ using the product-limit form, while the cumulative hazard
$c(t)$ is a sum.
\begin{align*}
    p(t) &= p(0)\prod_{s<=t} [I + dA(s)] \\
         &= p(0) \prod_{s<=t} H(s) \\
    c(t) &= \sum_{s<=t} dA(s)
\end{align*}
Where $p$ is a row vector and $H$ is the multi-state hazard matrix.  
$H(t)$ is a simple transition matrix.  
Row $j$ of $H$ describes the outcome of everyone who was in state $j$ at
time $t-0$; and is the fraction of them who are in states $1, 2, \ldots$
at time $t+0$.  
Let $Y_{ij}(t)$ be the indicator function which is 1 if subject $i$
is in state $j$ at time $t-0$, then
\begin{equation}
  H_{jk}(t) = \frac{\sum_i w_i Y_{ij}(t) Y_{ik}(t+)}
                  {\sum_i w_i Y_{ij}(t)} \label{H}
\end{equation}
Each row of $H$ sums to 1: everyone has to go somewhere. 
This formula collapses to the Kaplan-Meier in the simple case where $p(t)$ is a
vector of length 2 with state 1 = alive and state 2 = dead. 

The variance is based on per-subject influence.  Since $p(t)$ is a vector
the influence can be written as a matrix with one row per subject and
one column per state.
$$ U_{ij}(t) \equiv \frac{\partial p_j(t)}{\partial w_i}. $$
This can be calculate using a recursive formula.
First, the derivative of a matrix product $AB$ is $d(A)B + Ad(B)$ where
$d(A)$ is the elementwise derivative of $A$ and similarly for $B$.
(Write out each element of the matrix product.)
Since $p(t) = p(t-)H(t)$, the $i$th row of U satisfies
\begin{align}
  U_i(t) &= \frac{\partial p(t)}{\partial w_i} \nonumber \\
         &= \frac{\partial p(t-)}{\partial w_i} H(t) + 
           p(t-) \frac{\partial H(t)}{\partial w_i} \nonumber \\
         &= U_i(t-) H(t) +  p(t-) \frac{\partial H(t)}{\partial w_i} 
           \label{ci}
\end{align}  
The first term of \ref{ci} collapses to ordinary matrix multiplication. 
The second term does not: each at risk subject has a unique matrix derivative
$\partial H$; $n$ vectors of length $p$ can be arranged into a matrix, making
the code simple, but $n$
$p$ by $p$ matrices are not so neat.
However, note that
\begin{enumerate}
\item $\partial H$ is zero for anyone not in the risk set, since their
  weight does not appear in $H$.
\item Each subject who is at risk will be in one (and only one) of the
  states at the event time, their weight only appears in that row of $H$.
  Thus for each at risk subject $\partial H$ has only one non-zero row.
\end{enumerate}
Say that the subject enters the given event time in state $j$ and ends it
in state $k$.
(For most subjects at most time poinnts $k=j$: if there are 100 at risk at 
time $t$ and 1 changes state, the other 99 stay put.)
Let $n_j(t)= \sum_i Y_{ij}(t)w_i$ be the weighted number of subjects
in state $j$, these are the contributers to row $j$ of $H$.
Using equation \ref{H}, the derivative of row $j$
with respect to the subject is $(1_k - H_j)/n_j$
where $1_k$ is a vector with 1 in position $k$.
The product of $p(t)$ with this matrix is the vector
$p_j(t)(1_k - H_j)/n_j$.
The second term thus turns out to be fairly simple to compute, but I have
not seen a way to write it in a compact matrix form

The weighted sum of each column of $U$ will be zero (if computed correctly)
and the weighted sum of squares for each column will be the infinitesimal
jackknife estimate of variance for the elements of $p$.
The entire variance-covariance matrix for the states is $U'W^2U$ where 
$W$ is a diagonal 
matrix of weights, but we currently don't report that back.
Note that this is for sampling weights.  
If one has real case weights, where an integer weight of 2 means 2 observations
that were collapsed in to one row of data to save space, then the
variance is $U'WU$.  
Case weights were somewhat common in my youth due to small computer memory,
but I haven't seen such data in 20 years.

The residuals for the cumulative hazard are an easier computation, since each
hazard function stands alone.  In a multistate model with $k$ states there
are potentially $k(k-1)$ hazard functions arranged in a $k$ by $k$ matrix,
i.e., as used for the NA update; in the code both the hazard, the IJ scores
and the standard errors are kept as matrices with a column for each combination
that does occur.  At each event time only the rows of U2 that correspond to
the risk set will be updated.  

Below is the function for a single curve.
For the status variable a value if 0 is ``no event''.  
One nuisance in the function is that we need to ensure the
tapply command gives totals for all states, not just the ones present in the
data --- a call using the \code{subset} argument might not have all the states
--- which leads to using factor commands.
Another more confusing one is for multiple rows per subject data, where the 
cstate and U objects have only one row per subject; 
any given subject is only in one state at a time.
This leads to indices of [[atrisk]] for the set of rows in the risk set but
[[aindx]] for the subjects in the risk set, [[death]] for the rows that have
an event this time and [[dindx]] for the corresponding subjects.

The setup for (start, stop] data is a bit more work.  
We want to ensure that a given subject remains in the same group and that
they have a continuous period of observation.

If the input data was the result of a tmerge call, say, it might have a
lot of extra 'censored' rows.  For instance a subject whose state pattern
is (0, 5, 1), (5,10, 2), i.e., a transition to state 1 at day 5 and state 2
on day 10 might input as (0,2,0), (2,5,1), (5,6,0), (6,8,0), (8,10,2)
instead.  
These extra censors cause an
unnecessary row of output on days 2, 6, and 8.  
Remove these before going further.  

<<survfitCI-extracens>>=
# extra censors
indx <- order(id, Y[,2])   # in stop order
extra <- (survflag(Y[indx,], id[indx]) ==0 & (Y[indx,3] ==0))
# If a subject had obs of (a, b)(b,c)(c,d), and c was a censoring
#  time, that is an "extra" censoring/entry at c that we don't want
#  to count.  Deal with it by changing that subject
#  to (a,b)(b,d).  Won't change S(t), only the n.censored/n.enter count.
if (any(extra)) {
    e2 <- indx[extra]
    Y <- cbind(Y[-(1+e2),1], Y[-e2,-1])
    status <- status[-e2]
    X <- X[-e2]
    id <- id[-e2]
    istate <- istate[-e2]
    weights <- weights[-e2]
    indx <- order(id, Y[,2])
}
@ 

<<survfitCI-startstop>>=
# Now to work
for (i in levels(X)) {
    indx <- which(X==i)
#    temp <- docurve1(Y[indx,1], Y[indx,2], status[indx], 
#                          istate[indx], weights[indx], states, id[indx])
    curves[[i]] <- docurve2(Y[indx,1], Y[indx,2], status[indx], 
                            istate[indx],
                            weights[indx], states, id[indx], se.fit, 
                            influence, p0)
}
@ 
            
<<survfitCI-finish>>= 
# Turn the result into a survfit type object
grabit <- function(clist, element) {
    temp <-(clist[[1]][[element]]) 
    if (is.matrix(temp)) {
        do.call("rbind", lapply(clist, function(x) x[[element]]))
        }
    else {
        xx <- as.vector(unlist(lapply(clist, function(x) x[element])))
        if (inherits(temp, "table")) matrix(xx, byrow=T, ncol=length(temp))
        else xx
    }
}

# we want to rearrange the cumulative hazard to be in time order
#   with one column for each observed transtion.  
nstate <- length(states)
temp <- matrix(0, nstate, nstate)
indx1 <- match(rownames(mcheck$transitions), states)
indx2 <- match(colnames(mcheck$transitions), states, nomatch=0) #ignore censor
temp[indx1, indx2[indx2>0]] <- mcheck$transitions[,indx2>0]
ckeep <- which(temp>0)
names(ckeep) <- outer(1:nstate, 1:nstate, paste, sep='.')[ckeep]
#browser()

if (length(curves) ==1) {
    keep <- c("n", "time", "n.risk", "n.event", "n.censor", "pstate",
              "p0", "cumhaz", "influence.pstate")
    if (se.fit) keep <- c(keep, "std.err", "sp0")
    kfit <- (curves[[1]])[match(keep, names(curves[[1]]), nomatch=0)]
    names(kfit$p0) <- states
    if (se.fit) kfit$logse <- FALSE
    kfit$cumhaz <- t(kfit$cumhaz[ckeep,,drop=FALSE])
    colnames(kfit$cumhaz) <- names(ckeep)
}
else {    
    kfit <- list(n =      as.vector(table(X)),  #give it labels
                 time =   grabit(curves, "time"),
                 n.risk=  grabit(curves, "n.risk"),
                 n.event= grabit(curves, "n.event"),
                 n.censor=grabit(curves, "n.censor"),
                 pstate = grabit(curves, "pstate"),
                 p0     = grabit(curves, "p0"),
                 strata= unlist(lapply(curves, function(x)
                     if (is.null(x$time)) 0L else length(x$time))))
    kfit$p0 <- matrix(kfit$p0, ncol=nstate, byrow=TRUE,
                      dimnames=list(names(curves), states))
    if (se.fit) {
        kfit$std.err <- grabit(curves, "std.err")
        kfit$sp0<- matrix(grabit(curves, "sp0"),
                          ncol=nstate, byrow=TRUE)
        kfit$logse <- FALSE
    }

    # rearrange the cumulative hazard to be in time order, with columns
    #  for each transition
    kfit$cumhaz <- do.call(rbind, lapply(curves, function(x)
        t(x$cumhaz[ckeep,,drop=FALSE])))
    colnames(kfit$cumhaz) <- names(ckeep)
 
    if (influence) kfit$influence.pstate <- 
        lapply(curves, function(x) x$influence.pstate)
}                         

if (!missing(start.time)) kfit$start.time <- start.time
kfit$transitions <- mcheck$transitions

@ 

<<survfitCI-finish>>=
#       
# Last bit: add in the confidence bands:
#  
if (se.fit && conf.type != "none") {
    ci <- survfit_confint(kfit$pstate, kfit$std.err, logse=FALSE, 
                              conf.type, conf.int)
    kfit <- c(kfit, ci, conf.type=conf.type, conf.int=conf.int)
}
kfit$states <- states
kfit$type   <- attr(Y, "type")
kfit
@

The updated docurve function is here.
One issue that was not recognized originally is delayed entry.  If most
of the subjects start at time 0, say, but one of them starts at day 100
then that last subject is not a part of $p_0$.
We will define $p_0$ as the distribution of states just before the first
event. 
The code above has already ensured that each subject has a unique
value for istate, so we don't have to search for the right one.
The initial vector and leverage are 
\begin{align*}
  p_0 &= (\sum I{s_i=1}w_i, \sum I{s_i=2}w_i, \ldots)/ \sum w_i \\
  \frac{\partial p_0}{\partial w_k} &= 
  [(I{s_k=1}, I{s_k=2}, ...)- p_0]/\sum w_i
\end{align*}

The input data set is not necessarily sorted by time or subject.
The data has been checked so that subjects don't have gaps, however.
The cstate variable for each subject contains their first istate
value.  Only those intervals that overlap the first event time contribute
to $p_0$.   
Now: what to report as the ``time'' for the initial row.  The values for
it come from (first event time -0), i.e. all who are at risk at the 
smallest \code{etime} with status $>0$.
But for normal plotting the smallest start time seems to be a good
default.
In the usual (start, stop] data 
a large chunk of the subjects have a common start time.
However, if the first event doesn't happen for a while
and subjects are dribbling in, then the best point to start a plot
is open to debate.  Que sera sera.
<<survfitCI-compute>>=
docurve2 <- function(entry, etime, status, istate, wt, states, id, 
                     se.fit, influence=FALSE, p0) {
    timeset <- sort(unique(etime))
    nstate <- length(states)
    uid <- sort(unique(id))
    index <- match(id, uid)
    # Either/both of id and cstate might be factors.  Data may not be in
    #  order.  Get the initial state for each subject
    temp1 <- order(id, entry)
    temp2 <- match(uid, id[temp1])
    cstate <- (as.numeric(istate)[temp1])[temp2]  # initial state for each

    # The influence matrix can be huge, make sure we have enough memory
    if (influence) {
        needed <- max(nstate * length(uid), 1 + length(timeset))
        if (needed > .Machine$integer.max)
            stop("number of rows for the influence matrix is > the maximum integer")
    }
    storage.mode(wt) <- "double" # just in case someone had integer weights

    # Compute p0 (unless given by the user)
    if (is.null(p0)) {
        if (all(status==0))  t0 <- max(etime)  #failsafe
        else t0 <- min(etime[status!=0])  # first transition event
        at.zero <- (entry < t0 & etime >= t0) 
        wtsum <- sum(wt[at.zero])  # weights for a subject may change
        p0 <- tapply(wt[at.zero], istate[at.zero], sum) / wtsum
        p0 <- ifelse(is.na(p0), 0, p0)  #for a state not in at.zero, tapply =NA
    }
    # initial leverage matrix
    nid <- length(uid)
    i0  <- matrix(0., nid, nstate)
    if (all(p0 <1)) {  #actually have to compute it
        who <- index[at.zero]  # this will have no duplicates
        for (j in 1:nstate) 
            i0[who,j] <- (ifelse(istate[at.zero]==states[j], 1, 0) - p0[j])/wtsum
    }
     
    storage.mode(cstate) <- "integer"
    storage.mode(status) <- "integer"
    # C code has 0 based subscripts
    if (influence) se.fit <- TRUE   # se.fit is free in this case

    fit <- .Call(Csurvfitci, c(entry, etime), 
                 order(entry) - 1L,
                 order(etime) - 1L,
                 length(timeset),
                 status,
                 as.integer(cstate) - 1L,
                 wt,
                 index -1L,
                 p0, i0,
                 as.integer(se.fit) + 2L*as.integer(influence))

    if (se.fit) 
        out <- list(n=length(etime), time= timeset, p0 = p0,
                    sp0= sqrt(colSums(i0^2)),
             pstate = fit$p, std.err=fit$std,
             n.risk = fit$nrisk,
             n.event= fit$nevent,
             n.censor=fit$ncensor,
             cumhaz = fit$cumhaz)
    else out <- list(n=length(etime), time= timeset, p0=p0,
             pstate = fit$p,
             n.risk = fit$nrisk, 
             n.event = fit$nevent, 
             n.censor= fit$ncensor, 
             cumhaz= fit$cumhaz)
    if (influence) {
        temp <-  array(fit$influence, 
                       dim=c(length(uid), nstate, 1+ length(timeset)),
                       dimnames=list(uid, NULL, NULL))
        out$influence.pstate <- aperm(temp, c(1,3,2))
    }
    out
}
@
