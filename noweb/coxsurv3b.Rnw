\subsubsection{Multi-state models}
Survival curves after a multi-state Cox model are more challenging,
particularly the variance.

The issue that consumes the most work and thought has been shared hazards.
When there is a shared hazard $A$$ for a set of transitions, the common 
baseline has standard form:
$$
  \lambda_A(t) = \frac{\sum_i dN_{ijk}(t)}{\sum Y_{ij}(t)exp(X_i \beta^{jk})}
$$
where $(jk)$ is the set of from:to hazards that are shared, $Y$ marks those
at risk for one of those transitions at this time point, $\beta$ is the
appropriate set of coefficients, and $dN$ are the
observed ones.  All very simple. There is an assumption that $X\beta$ is well
defined for subjects, whichever starting state that they are in.

We have 3 cases.
\begin{enumerate}
  \item no shared hazards: formula\$smap[1,] has no repeat values.      %$
  \item simple shared hazards: there are special coefficients with names
    like ``ph(1:3)'', that will get attached to the 1:3 transtion.  No variables
    associated with those coefficients appear in newdata.
  \item there are shared hazards, and the user has specified which covariates
    belong to the shared hazards by setting them to NA in newdata.
\end{enumerate}

Case 1 and 2 are dealt with using \code{baselinecoef}, a vector of 1s for case
1 and a vector of per stratum multipliers for case 2.
Say that baseline $A$ is associated with 5 different hazards, then the $H$
matrix will have 5 columns associated with $A$, and what is entered into
$H$ is $\lambda_A$ * baselinehazard * risk score from newdata.
The last part represents the subject of interest, for whom a curve is being
created.
In case 3, what is entered is $\lambda_A$ * mean(z), where z is the risk
score for a combined data set with newdata values + model data set for the NA;
mean within the stratum.  Now, z should be a constant in all cases we've
thought on, the mean is a failsafe.


Case 3 is 

<<survfit.coxphms>>=
survfit.coxphms <-
function(formula, newdata, se.fit=FALSE, conf.int=.95, individual=FALSE,
         stype=2, ctype, 
         conf.type=c("log", "log-log", "plain", "none", "logit", "arcsin"),
         censor=TRUE, start.time, id, influence=FALSE,
         na.action=na.pass, type, p0=NULL, time0=FALSE, ...) {

    Call <- match.call()
    Call[[1]] <- as.name("survfit")  #nicer output for the user
    object <- formula     #'formula' because it has to match survfit
    se.fit <- FALSE   #still to do
    if (missing(newdata))
        stop("multi-state survival requires a newdata argument")
    if (!missing(id)) 
        stop("using a covariate path is not supported for multi-state")
    temp <- object$smap["(Baseline)",] 
    baselinecoef <- rbind(temp, coef= 1.0)
    phbase <- rep(FALSE, nrow(object$cmap))
    if (any(duplicated(temp))) {
        # We have shared hazards
        # Any rows of cmap with names like ph(1:4) are special. The coefs they
        #  point to should be copied over to the baselinecoef vector.
        # There might not be such rows, by the way.
        pattern <- "^ph\\([0-9]+:[0-9]+\\)$"
        cname <- rownames(object$cmap)
        phbase <- grepl(pattern, cname) # this row points to a "ph" coef        
        for (i in which(phbase)) {
            # Say that this row (i) of cmap had label ph(1:4), and contains
            #   elements 0,0,0,0,0, 8,9.
            # This means that coefs 8 and 9 are special.  They should be
            #   plugged into a matching element of baselinecoef.
            #   The columns names of smap and cmap are identical, and tell us
            #   where to put them.
            j <- object$cmap[i,]
            baselinecoef[2, j>0] <- exp(object$coef[j])
        }
    }
      
    # process options, set up Y and the model frame for the original data
    <<survfit.coxph-setup1>>
    <<survfit.coxph-setup2>>
    istate <- model.extract(mf, "istate")

    #deal with start time, by throwing out observations that end before then
    if (!missing(start.time)) {
        if (!is.numeric(start.time) || length(start.time) !=1
            || !is.finite(start.time))
            stop("start.time must be a single numeric value")
        toss <- which(Y[,ncol(Y)-1] <= start.time)
        if (length(toss)) {
            n <- nrow(Y)
            if (length(toss)==n) stop("start.time has removed all observations")
            Y <- Y[-toss,,drop=FALSE]
            X <- X[-toss,,drop=FALSE]
            weights <- weights[-toss]
            oldid <- oldid[-toss]
            istate <- istate[-toss]
        }
    }
    
    # expansion of the X matrix with stacker, set up shared hazards
    <<survfit.coxphms-setupa>>

    # risk scores, mf2, and x2
    <<survfit.coxph-setup2c>>
    <<survfit.coxph-setup3>>

    <<survfit.coxphms-setup3b>>
    <<survfit.coxphms-result>>

    cifit$call <- Call
    class(cifit) <- c("survfitcoxms", "survfitms", "survfit")
    cifit
}
@ 
The third line \code{as.name('survfit')} causes the printout to say
`survfit' instead of `survfit.coxph'.                              %'

Notice that setup is almost completely shared with survival for single state
models.  The major change is that we use survfitAJ (non-Cox) to do all the
legwork wrt the tabulation values (number at risk, etc.),
while for the computation proper it is easier to make use of the same
expanded data set that coxph used for a multi-state fit.

<<survfit.coxphms-setupa>>=
# Rebuild istate using the survcheck routine, as a double check
# that the data set hasn't been modified
mcheck <- survcheck2(Y, oldid, istate)
transitions <- mcheck$transitions
if (!identical(object$states, mcheck$states))
    stop("failed to rebuild the data set")
if (is.null(istate)) istate <- mcheck$istate
else {
    # if istate has unused levels, mcheck$istate won't have them so they
    #  need to be dropped.
    istate <- factor(istate, object$states) 
    # a new level in state should only happen if someone has mucked up the
    #  data set used in the coxph fit
    if (any(is.na(istate))) stop("unrecognized initial state, data changed?")
}

# Let the survfitAJ routine do the work of creating the
#  overall counts (n.risk, etc).  The rest of this code then
#  replaces the surv and hazard components.
if (missing(start.time)) start.time <- min(Y[,2], 0)

if (is.null(weights)) weights <- rep(1.0, nrow(Y))
if (is.null(strata))  tempstrat <- rep(1L, nrow(Y))
else                  tempstrat <- strata

cifit <- survfitAJ(as.factor(tempstrat), Y, weights, 
                        id= oldid, istate = istate, se.fit=FALSE, 
                        start.time=start.time, p0=p0, time0= time0)

# For computing the  actual estimates it is easier to work with an
#  expanded data set.
# Replicate actions found in the coxph-multi-X chunk
# Note the dropzero=FALSE argument: if there is a transition with no 
#  covariates we still need it expanded; this differs from coxph.
# A second differnence is tstrata: force stacker to think that every
#  transition is a unique hazard, so that it does proper expansion.
cluster <- model.extract(mf, "cluster")
tstrata <- object$smap
tstrata[1,] <- 1:ncol(tstrata)
xstack <- stacker(object$cmap, tstrata, as.integer(istate), X, Y,
                  as.integer(strata),
                  states= object$states, dropzero=FALSE)
if (length(position) >0)
    position <- position[xstack$rindex]   # id was required by coxph
X <- xstack$X
Y <- xstack$Y
strata <- strata[xstack$rindex]  # strat in the model, other than transitions
transition <- xstack$transition
istrat <- xstack$strata
if (length(offset)) offset <- offset[xstack$rindex]
if (length(weights)) weights <- weights[xstack$rindex]
if (length(cluster)) cluster <- cluster[xstack$rindex]
oldid <- oldid[xstack$rindex]
if (robust & length(cluster)==0) cluster <- oldid
@

Fix up the X matrix to avoid huge values.  In the single state case this
is fairly straightforward: use $(X-1m')\beta = X\beta - m'\beta$ where
$m$ is the vector of centering constants found in the 
\code{object\$means} component.
However, in multi-state there will often be covariates that are part of one
transition but not another, and if one of them is wild we will want different
centering for each transition.
(Not yet implemented).
<<survfit.coxph-setup2d>>=
if (length(object$means) ==0) { # a model with only an offset term
    # Give it a dummy X so the rest of the code goes through
    #  (This case is really rare)
    # se.fit <- FALSE
    X <- matrix(0., nrow=n, ncol=1)
    if (is.null(offset)) offset <- rep(0, n)
    xcenter <- mean(offset)
    coef <- 0.0
    varmat <- matrix(0.0, 1, 1)
    risk <- rep(exp(offset- mean(offset)), length=n)
}
else {
    varmat <- object$var
    beta <- ifelse(is.na(object$coefficients), 0, object$coefficients)
    if (is.null(offset)) xcenter <- sum(object$means * beta)
    else xcenter <- sum(object$means * beta)+ mean(offset)
    if (!is.null(object$frail)) {
       keep <- !grepl("frailty(", dimnames(X)[[2]], fixed=TRUE)
       X <- X[,keep, drop=F]
    }
        
    if (is.null(offset)) risk <- c(exp(X%*% beta - xcenter))
    else     risk <- c(exp(X%*% beta + offset - xcenter))
}
@ 

The survfit.coxph-setup3 chunk, shared with single state Cox models, has created
an mf2 model frame and an x2 matrix. 
For multi-state, we ignore any strata variables in mf2.
Create a matrix of risk scores, number of subjects by number of transitions.
Different transitions often have different coefficients, so there is a risk
score vector per transition.

<<survfit.coxphms-setup3b>>=
if (has.strata && any(stangle$vars %in% names(mf2))){
    mf2 <- mf2[is.na(match(names(mf2), stangle$vars))]
    mf2 <- unique(mf2)
    x2 <- unique(x2)
}
temp <- coef(object, matrix=TRUE)[!phbase,,drop=FALSE] # ignore missing coefs
# temp will be a matrix of coefficients, with ncol = number of transtions
#  and nrow = the covariate set of a "normal" Cox model.
# x2 will have one row per desired curve and one col per 'normal' covariate.
risk2 <- exp(x2 %*% ifelse(is.na(temp), 0, temp) - xcenter)
# risk2 has a risk score with rows= curve and cols= transition
@ 

At this point we have several parts to keep straight.  The data set has been
expanded into a new X and Y.
\begin{itemize}
  \item \code{strata} contains any strata that were specified by the user
    in the original fit. We do completely separate computations for each
    stratum: the time scale starts over, nrisk, etc.  Each has a separate
    call to the multihaz function.
  \item \code{transtion} contains the transition to which each observation
    applies
  \item \code{istrat} comes from the xstack routine, and marks each
    strata * baseline hazard combination.
  \item \code{baselinecoef} maps from baseline hazards to transitions.  It
    has one column per transition, which baseline hazard it points to, and a
    multiplier. Most multipliers will be 1.
  \item \code{hfill} is constructed below. It contains the row/column to which
    each column of baselinecoef is mapped, within the H matrix used to compute
    P(state).
\end{itemize}
The coxph routine fits all strata and transitions at once, since the loglik is
a sum over strata.  This routine does each stratum separately.

<<survfit.coxphms-result>>=
# make the expansion map.  
# The H matrices we will need are nstate by nstate, at each time, with
# elements that are non-zero only for observed transtions.
states <- object$states
nstate <- length(states)
from <- as.numeric(sub(":.*$", "", colnames(object$smap)))
to   <- as.numeric(sub("^.*:", "", colnames(object$smap)))
hfill <- cbind(from, to)

if (individual) {
    stop("time dependent survival curves are not supported for multistate")
}
ny <- ncol(Y)
if (is.null(strata)) {
    fit <- multihaz(Y, X, position, weights, risk, istrat, ctype, stype,
                    baselinecoef, hfill, x2, risk2, varmat, nstate, se.fit, 
                    cifit$p0, cifit$time)
    cifit$pstate <- fit$pstate
    cifit$cumhaz <- fit$cumhaz
}
else {
    if (is.factor(strata)) ustrata <- levels(strata)
    else                   ustrata <- sort(unique(strata))
    nstrata <- length(cifit$strata)
    itemp <- rep(1:nstrata, cifit$strata)
    timelist <- split(cifit$time, itemp)
    ustrata <- names(cifit$strata)
    tfit <- vector("list", nstrata)
    for (i in 1:nstrata) {
        indx <- which(strata== ustrata[i])  # divides the data
        tfit[[i]] <- multihaz(Y[indx,,drop=F], X[indx,,drop=F],
                              position[indx], weights[indx], risk[indx],
                              istrat[indx], ctype, stype, baselinecoef, hfill,
                              x2, risk2, varmat, nstate, se.fit,
                              cifit$p0[i,], timelist[[i]])
    }

    # do.call(rbind) doesn't work for arrays, it loses a dimension
    ntime <- length(cifit$time)
    cifit$pstate <- array(0., dim=c(ntime, dim(tfit[[1]]$pstate)[2:3]))
    cifit$cumhaz <- array(0., dim=c(ntime, dim(tfit[[1]]$cumhaz)[2:3]))
    rtemp <- split(seq(along=cifit$time), itemp)
    for (i in 1:nstrata) {
        cifit$pstate[rtemp[[i]],,] <- tfit[[i]]$pstate
        cifit$cumhaz[rtemp[[i]],,] <- tfit[[i]]$cumhaz
    }
}

cifit$newdata <- newdata
@

Finally, a routine that does all the actual work.
\begin{itemize}
  \item The first 5 variables are for the data set that the Cox model was built 
    on: y, x, position, risk score, istrat.  
    Position is a flag for each obs. Is it the first of a connected string
    such as (10, 12) (12,19) (19,21), the last of such a string, both, 
    or neither.  1*first + 2*last.   This affects whether an obs is labeled
    as censored or not in user printout, nothing else.  (That part has actually
    already been done via the survfitAJ call.)
  \item x2 and risk2 are the covariates and risk scores for the predicted 
    values.  These do not involve any ph(a:b) coefficients.
  \item baselinecoef encodes shared hazards
   \item hfill control mapping from fitted hazards to 
    transitions and probabilities
  \item p0 will be NULL if the user did not specifiy it.  
  \item vmat is only needed for standard errors
  \item utime is the set of time points desired
\end{itemize}

The cn matrix below contains all the subtotals we need.
Say that transitions 4, 5, and 6 have a shared hazard, with bcoef[2,] values
of 1, 1.3, .4 (the first coef is always 1).
Then the underlying hazard will base = (events[3] + events[4] + events[5])/
(nrisk[3] + 1.3* nrisk[4] + .4*nrisk[5]),
and the 3 individual hazards are 1*base, 1.3*base and .4*base.
If there are no shared hazards this can be computed more simply of course.

<<survfit.coxphms>>=
# Compute the hazard  and survival functions 
multihaz <- function(y, x, position, weight, risk, istrat, ctype, stype, 
                     bcoef, hfill, x2, risk2, vmat, nstate, se.fit, p0, utime) {
    ny <- ncol(y)
    sort2 <- order(istrat, y[,ny-1L]) -1L
    ntime <- length(utime)
    storage.mode(weight) <- "double"  #failsafe

    # this returns all of the counts we might desire.
    if (ny ==2) {
        fit <- .Call(Ccoxsurv1, utime, y, weight, sort2, istrat, x, risk)
        cn <- fit$count  
        dim(cn) <- c(length(utime), fit$ntrans, 10) 
    }
    else {    
        sort1 <- order(istrat, y[,1]) -1L
        fit <- .Call(Ccoxsurv2, utime, y, weight, sort1, sort2, position, 
                        istrat, x, risk)
        cn <- fit$count  
        dim(cn) <- c(length(utime), fit$ntrans, 12) 
    }
    # cn is returned as a matrix since there is an allocMatrix C macro, but
    #  no allocArray macro.  So we first reset the dimensions.
    # The first dimension is time
    # Second is the transition, same order as columns of bcoef
    # Third is the count type: 1-3 = at risk (unweighted, with case weights,
    #  with casewt * risk wt), 4-6 = events (unweighted, case, risk), 
    #  7-8 = censored events, 9-10 = censored, 11-12 = Efron

    # We will use events/(at risk) = cn[,,5]/cn[,,3] a few lines below; avoid 0/0
    # If there is no one at risk there are no events, obviously.
    # cn[,,1] is the safer check since it is an integer, but if there are weights
    #  and a subject with weight=0 were the only one at risk, we need cn[,,2]
    # (Users should never use weights of 0, but someone, somewhere, will do it.)
    none.atrisk <- (cn[,,1]==0 | cn[,,2]==0)
    if (ctype ==1) {
        denom1 <- ifelse(none.atrisk, 1, cn[,,3])   # avoid a later 0/0
        denom2 <- ifelse(none.atrisk, 1, cn[,,3]^2)
    } else {
        denom1 <- ifelse(none.atrisk, 1, cn[,,9])
        denom2 <- ifelse(none.atrisk, 1, cn[,,10])
    }

    # We want to avoid 0/0. If there is no one at risk (denominator) then
    # by definition there will be no events (numerator), and that element of
    # the hazard is by definintion also 0.
    if (any(duplicated(bcoef[1,]))) {
        # there are shared hazards: we have to collapse and then expand
        if (all(bcoef[1,] == bcoef[1,1])) design <- matrix(1, nrow=ncol(bcoef))
        else design <- model.matrix(~factor(zed) -1, data.frame(zed=bcoef[1,]))
        colnames(design) <- 1:ncol(design)  # easier to read when debuggin
        events <- cn[,,5] %*% design
        if (ctype==1) atrisk <- cn[,,3]  %*% design
        else          atrisk <- cn[,,9] %*% design
        basehaz <- events/ifelse(atrisk<=0, 1, atrisk)
        hazard <- basehaz[,bcoef[1,]] * rep(bcoef[2,], each=nrow(basehaz))
    }                                  
    else {
        if (ctype==1) hazard <- cn[,,5]/ifelse(cn[,,3]<=0, 1, cn[,,3])
        else          hazard <- cn[,,5]/ifelse(cn[,,9] <=0, 1, cn[,,9])
    }

    # Expand the result, one "hazard set" for each row of x2
    nx2 <- nrow(x2)
    h2 <- array(0, dim=c(nrow(hazard), nx2, ncol(hazard)))
    S <- double(nstate)  # survival at the current time
    S2 <- array(0, dim=c(nrow(hazard), nx2, nstate))
 
    H <- matrix(0, nstate, nstate)
    if (stype==2) {
        H[hfill] <- colMeans(hazard)    # dummy H to drive esetup
        diag(H) <- diag(H) -rowSums(H)
        esetup <- survexpmsetup(H)
    }

    for (i in 1:nx2) {
        h2[,i,] <- apply(hazard * rep(risk2[i,], each=ntime), 2, cumsum)
        if (FALSE) {  # if (se.fit) eventually
            d1 <- fit$xbar - rep(x[i,], each=nrow(fit$xbar))
            d2 <- apply(d1*hazard, 2, cumsum)
            d3 <- rowSums((d2%*% vmat) * d2)
            v2[jj,] <- (apply(varhaz[jj,],2, cumsum) + d3) * (risk2[i])^2
        }

        S <- p0
        for (j in 1:ntime) {
            if (any(hazard[j,] > 0)) { # hazard =0 for censoring times
                H[,] <- 0.0
                H[hfill] <- hazard[j,] *risk2[i,]
                if (stype==1) {
                    diag(H) <- pmax(0, 1.0 - rowSums(H))
                    S <- as.vector(S %*% H)  # don't keep any names
                }
                else {
                    diag(H) <- 0.0 - rowSums(H)
                    #S <- as.vector(S %*% expm(H))  # dgeMatrix issue
                    S <- as.vector(S %*% survexpm(H, 1, esetup))
                }
            }
            S2[j,i,] <- S
        }
    }
    rval <- list(time=utime, xgrp=rep(1:nx2, each=nrow(hazard)),
                 pstate=S2, cumhaz=h2)
    #if (se.fit) rval$varhaz <- v2
    rval
}
@


