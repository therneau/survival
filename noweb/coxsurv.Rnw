
\subsection{Predicted survival}
The \code{survfit} method for a Cox model produces individual survival
curves.  As might be expected these have much in common with
ordinary survival curves, and share many of the same methods.
The primary differences are first that a predicted curve always refers
to a particular set of covariate values.   
It is often the case that a user wants multiple values at once, in 
which case the result will be a matrix of survival curves with a row
for each time and a column for each covariate set.
The second is that the computations are somewhat more difficult.

The input arguments are
\begin{description}
  \item[formula] a fitted object of class `coxph'.  The argument name of 
    `formula' is historic, from when the survfit function was not a generic
    and only did Kaplan-Meier type curves.
  \item[newdata] contains the data values for which curves should be
    produced, one per row
  \item[se.fit] TRUE/FALSE, should standard errors be computed.
  \item[individual] a particular option for time-dependent covariates
  \item[stype] survival type for the formula 1=direct 2= exp
  \item[ctype] cumulative hazard, 1=Nelson-Aalen, 2= corrected for ties
  \item[censor] if FALSE, remove any times that have no events from the
    output.  This is for 
    backwards compatability with older versions of the code.
  \item[id] replacement and extension for the individual argument
  \item[start.time] Start a curve at a later timepoint than zero.
  \item[id] replacement for the individual option
  \item[influence] whether to return the influence matrix
\end{description}
All the other arguments are common to all the methods, refer to the 
help pages.

Other survival routines have id and cluster options; this routine inherits
those variables from coxph.  If coxph did a robust variance, this routine
will do one also.

<<survfit.coxph>>=
survfit.coxph <-
  function(formula, newdata, se.fit=TRUE, conf.int=.95, individual=FALSE,
            stype=2, ctype, 
            conf.type=c("log", "log-log", "plain", "none", "logit", "arcsin"),
            censor=TRUE, start.time, id, influence=FALSE,
            na.action=na.pass, type, ...) {

      Call <- match.call()
      Call[[1]] <- as.name("survfit")  #nicer output for the user
      object <- formula     #'formula' because it has to match survfit

      <<survfit.coxph-setup1>>
      <<survfit.coxph-setup2>>
      <<survfit.coxph-setup2b>>
      <<survfit.coxph-setup2c>>
      <<survfit.coxph-setup3>>
      if (missing(newdata)) risk2 <- 1
      else {
          if (length(object$means)) 
              risk2 <- exp(c(x2 %*% beta) + offset2 - xcenter)
          else risk2 <- exp(offset2 - xcenter)
      }
      <<survfit.coxph-result>>
      <<survfit.coxph-finish>>
      }
@ 
The third line \code{as.name('survfit')} causes the printout to say
`survfit' instead of `survfit.coxph'.                              %'

The setup for the has three main phases, first of course to sort out the
options the user has given us, second to rebuild the
data frame, X matrix, etc from the original Cox model, and third to 
create variables from the new data set.
In the code below x2, y2, strata2, id2, etc. are variables from the
new data, X, Y, strata etc from the old.  One exception to the pattern
is id= argument, oldid = id from original data, id2 = id from new.

If the newdata argument is missing we use \code{object\$means} as the
default value.  This choice has lots of statistical shortcomings,
particularly in a stratified model, but is common in other
packages and a historic option here.
If stype is missing we use the standard approach of exp(cumulative hazard),
and ctype is pulled from the Cox model.
That is, the \code{coxph} computation used for \code{ties='breslow'} is
the same as the Nelson-Aalen hazard estimate, and
the Efron approximation the tie-corrected hazard.

One particular special case (that gave me fits for a while) is when there
are non-heirarchical models, for example \code{~ age + age:sex}.  
The fit of such a model will \emph{not} be the same using the variable
\code{age2 <- age-50}; I originally thought it was a flaw induced by my 
subtraction.  
The routine simply cannot give a sensible curve for a model like this.
The issue continued to surprise me each time I rediscovered it,
leading to an error message for my own protection.  I'm
not convinced at this time that there is a sensible survival curve
that \emph{could} be calculated for such a model.
A model with \code{age + age:strata(sex)} will be ok, because the
coxph routine treats this last term as though it had a * in it, i.e.,
fits a stratified model.

<<survfit.coxph-setup1>>=
Terms  <- terms(object)
robust <- !is.null(object$naive.var)   # did the coxph model use robust var?

if (!is.null(attr(object$terms, "specials")$tt))
    stop("The survfit function can not process coxph models with a tt term")

if (!missing(type)) {  # old style argument
    if (!missing(stype) || !missing(ctype))
        warning("type argument ignored")
    else {
        temp1 <- c("kalbfleisch-prentice", "aalen", "efron",
                   "kaplan-meier", "breslow", "fleming-harrington",
                   "greenwood", "tsiatis", "exact")
        
        survtype <- match(match.arg(type, temp1), temp1)
        stype <- c(1,2,2,1,2,2,2,2,2)[survtype]
        if (stype!=1) ctype <-c(1,1,2,1,1,2,1,1,1)[survtype]
    }
}
if (missing(ctype)) {
    # Use the appropriate one from the model
    temp1 <- match(object$method, c("exact", "breslow", "efron"))
    ctype <- c(1,1,2)[temp1]
}
else if (!(ctype %in% 1:2)) stop ("ctype must be 1 or 2")

if (!se.fit) conf.type <- "none"
else conf.type <- match.arg(conf.type)

tfac <- attr(Terms, 'factors')
temp <- attr(Terms, 'specials')$strata 
has.strata <- !is.null(temp)
if (has.strata) {
    stangle = untangle.specials(Terms, "strata")  #used multiple times, later
    # Toss out strata terms in tfac before doing the test 1 line below, as
    #  strata end up in the model with age:strat(grp) terms or *strata() terms
    #  (There might be more than one strata term)
    for (i in temp) tfac <- tfac[,tfac[i,] ==0]  # toss out strata terms
}
if (any(tfac >1))
    stop("not able to create a curve for models that contain an interaction without the lower order effect")

Terms <- object$terms
n <- object$n[1]
if (!has.strata) strata <- rep(0L, n)
else strata <- object$strata

missid <- missing(id) # I need this later, and setting id below makes
                      # "missing(id)" always false
if (!missid & !missing(individual))
    warning("the `id' option supersedes `individual'")

if (!missid) individual <- TRUE
else if (missid && individual) id <- rep(0,n)  #dummy value
else id <- NULL

if (individual & missing(newdata)) {
    stop("the id and/or individual options only make sense with new data")
}
@ 

In two places below we need to know if there are strata by covariate
interactions, which requires looking at attributes of the terms
object.
The factors attribute will have a row for the strata variable, or
maybe more than one (multiple strata terms are legal).  If it has
a 1 in a column that corresponds to something of order 2 or
greater, that is a strata by covariate interaction.
<<survfit.coxph-setup1>>=
if (has.strata) {
    temp <- attr(Terms, "specials")$strata
    factors <- attr(Terms, "factors")[temp,]
    strata.interaction <- any(t(factors)*attr(Terms, "order") >1)
}
@ 


I need to retrieve a copy of the original data. 
We always need the $X$ matrix and $y$, both of which might be found in 
the data object.
If the fit was a multistate model,
the original call included either strata, offset, weights, or id, 
or if either $x$ or $y$ are missing from the \code{coxph} object, 
then the model frame will need to be reconstructed.
We have to use \code{object['x'}] instead of \texttt{object\$x} since
the latter will
pick off the \code{xlevels} component if the \code{x} component is missing 
(which is the default).
<<survfit.coxph-setup1>>=
coxms <- inherits(object, "coxphms")
if (coxms || is.null(object$y) || is.null(object[['x']]) ||
    !is.null(object$call$weights) || !is.null(object$call$id) ||
    (has.strata && is.null(object$strata)) ||
    !is.null(attr(object$terms, 'offset'))) {
    
    mf <- stats::model.frame(object)
    }
else mf <- NULL  #useful for if statements later
@ 

For a single state model we can grab
the X matrix off the model frame, for multistate some more work
needs to be done.  
We have to repeat some lines from coxph, but to do that we need some
further material.
<<survfit.coxph-setup2>>=
position <- NULL
if (is.null(mf)) {
    weights <- rep(1., n)
    offset <- rep(0., n)
    X <- object[['x']]
    Y <- object[['y']]
}
else {
    weights <- model.weights(mf)
    if (is.null(weights)) weights <- rep(1.0, n)
    offset <- model.offset(mf)
    if (is.null(offset)) offset <- rep(0., n)
    X <- model.matrix.coxph(object, data=mf)
    Y <- model.response(mf)
    oldid <- model.extract(mf, "id")
    if (length(oldid) && ncol(Y)==3) position <- survflag(Y, oldid)
    else position <- NULL
    if (nrow(Y) != object$n[1]) 
        stop("Failed to reconstruct the original data set")
    if (has.strata) {
        if (length(strata)==0) {
            if (length(stangle$vars) ==1) strata <- mf[[stangle$vars]]
            else strata <- strata(mf[, stangle$vars], shortlabel=TRUE)
        }
    }

}
@ 

If a model frame was created, then it is trivial to grab \code{y}
from the new frame and compare it to \code{object\$y} from the
original one.  This is to avoid nonsense results that arise
when someone changes the data set under our feet. 
We can only check the size: with the addition of aeqSurv other packages
were being flagged for tiny discrepancies.
Later note: this check does not work for multi-state models, and we don't
\emph{have} to have it.  Removed by using if (FALSE) so as to preserve
the code for future consideration.
<<survfit.coxph-setup2b>>=
if (FALSE) {
if (!is.null(mf)){
    y2 <- object[['y']]
    if (!is.null(y2)) {
        if (ncol(y2) != ncol(Y) || length(y2) != length(Y))
            stop("Could not reconstruct the y vector")
    }
}
}
type <- attr(Y, 'type')
if (!type %in% c("right", "counting", "mright", "mcounting"))
    stop("Cannot handle \"", type, "\" type survival data")
if (type=="right" || type== "mright") individual <- FALSE

if (!missing(start.time)) {
    if (!is.numeric(start.time) || length(start.time) > 1)
        stop("start.time must be a single numeric value")
    # Start the curves after start.time
    # To do so, remove any rows of the data with an endpoint before that
    #  time.
    if (ncol(Y)==3) {
        keep <- Y[,2] > start.time
        Y[keep,1] <- pmax(Y[keep,1], start.time)
    }
    else keep <- Y[,1] > start.time
    if (!any(Y[keep, ncol(Y)]==1)) 
        stop("start.time argument has removed all endpoints")
    Y <- Y[keep,,drop=FALSE]
    X <- X[keep,,drop=FALSE]
    offset <- offset[keep]
    strata <- strata[keep]
    if (length(id) >0 ) id <- id[keep]
    if (length(position)) position <- position[keep]
    n <- nrow(Y)
}
@

In the above code we see id twice. The first, kept as \code{oldid} is the
identifier variable for subjects in the original data set, and is needed
whenever it contained subjects with more than one row.  
The second is the user variable of this call, and is used to define multiple
rows for a new subject.  The latter usage should be rare but we need to
allow for it.

If a variable is deemed redundant the \code{coxph} routine will have set its
coefficient to NA as a marker. 
We want to ignore that coefficient: treating it as a zero has the 
desired effect.
Another special case is a null model, having either ~1 or only an offset
on the right hand side.  In that case we create a dummy covariate to
allow the rest of the code to work without special if/else.
The last special case is a model with a sparse frailty term.  We treat
the frailty coefficients as 0 variance (in essence as an offset).
The frailty is removed from the model variables but kept in the risk score.
This isn't statistically very defensible, but it is backwards compatatble. %'
A non-sparse frailty does not need special code and works out like any
other variable.  

Center the risk scores by subtracting $ \overline x \hat\beta$ from each.
The reason for this is to avoid huge values when calculating $\exp(X\beta)$;
this would happen if someone had a variable with a mean of 1000 and a
variance of 1. 
Any constant can be subtracted, mathematically the results are identical as long
as the same values are subtracted from the old and new $X$ data.  
The mean is used because it is handy, we just need to get $X\beta$ in the
neighborhood of zero.

<<survfit.coxph-setup2c>>=
if (length(object$means) ==0) { # a model with only an offset term
    # Give it a dummy X so the rest of the code goes through
    #  (This case is really rare)
    # se.fit <- FALSE
    X <- matrix(0., nrow=n, ncol=1)
    xcenter <- mean(offset)
    coef <- 0.0
    varmat <- matrix(0.0, 1, 1)
    risk <- rep(exp(offset- mean(offset)), length=n)
}
else {
    varmat <- object$var
    beta <- ifelse(is.na(object$coefficients), 0, object$coefficients)
    xcenter <- sum(object$means * beta)+ mean(offset)
    if (!is.null(object$frail)) {
       keep <- !grepl("frailty(", dimnames(X)[[2]], fixed=TRUE)
       X <- X[,keep, drop=F]
    }
        
    risk <- c(exp(X%*% beta + offset - xcenter))
}
@ 

The \code{risk} vector and \code{x} matrix come from the original data, and are
the raw data for the survival curve and its variance.  
We also need the risk score $\exp(X\beta)$ for the target subject(s).
\begin{itemize}
  \item For predictions with time-dependent covariates the user will have 
    either included an \code{id} statement (newer style) or specified the
    \code{individual=TRUE} option.  If the latter, then \code{newdata} is
    presumed to contain only a single indivual represented by multiple
    rows.  If the former then the \code{id} variable marks separate individuals.
    In either case we need to retrieve
    the covariates, strata, and repsonse from the new data set.
  \item For ordinary predictions only the covariates are needed.
  \item If newdata is not present we assume that this is the ordinary case, and
    use the value of \code{object\$means} as the default covariate set.  This is
    not ideal statistically since many users view this as an
    ``average'' survival curve, which it is not.
\end{itemize}

When grabbing [newdata] we want to use model.frame processing, both to 
handle missing values correctly and, perhaps more importantly, to correctly
map any factor variables between the original fit and the new data.  (The
new data will often have only one of the original levels represented.)
Also, we want to correctly handle data-dependent nonlinear terms such as
ns and pspline.
However, the simple call found in predict.lm, say,
\code{model.frame(Terms, data=newdata, ..} isn't used here
for a few reasons. 
The first is a decision on our part that the user should not have
to include unused terms in the newdata: sometimes we don't need the
response and sometimes we do.  
Second, if there are strata, the user may or may not
have included strata variables in their data set and we need to
act accordingly.
The third is that we might have an \code{id} statement in this
call, which is another variable to be fetched.
At one time we dealt with cluster() terms in the formula, but the coxph
routine has already removed those for us.
Finally, note that there is no ability to use sparse frailties and newdata together;
it is a hard case and so rare as to not be worth it.

First, remove unnecessary terms from the orginal model formula. 
If \code{individual} is false then the repsonse variable can go.

The dataClasses and predvars attributes, if present, have elements
in the same order as the first dimension of the ``factors'' attribute
of the terms.
Subscripting the terms argument does not preserve dataClasses or 
predvars, however.  Use the pre and post subscripting factors attribute
to determine what elements of them to keep.
The predvars component is a call objects with one element for each
term in the formula, so y ~ age + ns(height) would lead to a predvars
of length 4, element 1 is the call itself, 2 would be y, etc.
The dataClasses object is a simple list.

<<survfit.coxph-setup3>>= 
if (missing(newdata)) {
    if (length(object$means)) {
        mf2 <- as.list(object$means)   #create a dummy newdata
        names(mf2) <- names(object$coefficients)
        mf2 <- as.data.frame(mf2)
        x2 <- matrix(object$means, 1)
    }
    else { # nothing but an offset
        mf2 <- data.frame(X=0)
        x2 <- 0
    }
    offset2 <- 0
    found.strata <- FALSE  
}
else {
    if (!is.null(object$frail))
        stop("Newdata cannot be used when a model has frailty terms")

    Terms2 <- Terms 
    if (!individual)  Terms2 <- delete.response(Terms)
    <<survfit.coxph-newdata2>>
}
@ 

For backwards compatability, I allow someone to give an ordinary vector
instead of a data frame (when only one curve is required).  In this case
I also need to verify that the elements have a name. 
Then turn it into a data frame, like it should have been from the beginning.
(Documentation of this ability has been suppressed, however.  I'm hoping 
people forget it ever existed.) 
<<survfit.coxph-newdata2>>=
if (is.vector(newdata, "numeric")) {
    if (individual) stop("newdata must be a data frame")
    if (is.null(names(newdata))) {
        stop("Newdata argument must be a data frame")
    }
    newdata <- data.frame(as.list(newdata), stringsAsFactors=FALSE)
}
@ 

Finally get my new model frame mf2.
We allow the
user to leave out any strata() variables if they so desire,
\emph{if} there are no strata by covariate interactions.

How does one check if the strata variables are or are not available in
the call?
My first attempt at this was to wrap the call in a try() construct and
see if it failed.  This doesn't work. 
\begin{itemize}
  \item What if there is no strata variable in newdata, but they do have, 
    by bad luck, a variable of the same name in their main directory?
  \item It would seem like changing the environment to NULL would be wise,
    so that we don't find variables anywhere but in the data argument,
    a sort of sandboxing.  Not wise: you then won't find functions like ``log''.
  \item We don't dare modify the environment of the formula at all.
    It is needed for the sneaky caller who uses his own function
    inside the formula, 'mycosine' say, and that function can only be 
    found if we retain the environment.  
\end{itemize}
One way out of this is to evaluate each of the strata terms
(there can be more than one) one at a time, in an environment that knows
nothing except "list" and a fake definition of "strata", and newdata.
Variables that are part of the global environment won't be found.
I even watch out for the case of either "strata" or "list" is the name of
the stratification variable, which causes my fake strata function to 
return a function when said variable is not in newdata. The
variable found.strata is true if ALL the strata are found, set it to
false if any are missing.

<<survfit.coxph-newdata2>>= 
if (has.strata) {
    found.strata <- TRUE
    tempenv <- new.env(, parent=emptyenv())
    assign("strata", function(..., na.group, shortlabel, sep)
        list(...), envir=tempenv)
    assign("list", list, envir=tempenv)
    for (svar in stangle$vars) {
        temp <- try(eval(parse(text=svar), newdata, tempenv),
                    silent=TRUE)
        if (!is.list(temp) || 
            any(unlist(lapply(temp, class))== "function"))
            found.strata <- FALSE
    }
    
    if (!found.strata) {
        ss <- untangle.specials(Terms2, "strata")
        Terms2 <- Terms2[-ss$terms]
    }
}

tcall <- Call[c(1, match(c('id', "na.action"), 
                             names(Call), nomatch=0))]
tcall$data <- newdata
tcall$formula <- Terms2
tcall$xlev <- object$xlevels[match(attr(Terms2,'term.labels'),
                                   names(object$xlevels), nomatch=0)]
tcall[[1L]] <- quote(stats::model.frame)
mf2 <- eval(tcall)
@    

Now, finally, extract the \code{x2} matrix from the just-created frame.
<<survfit.coxph-setup3>>=
if (has.strata && found.strata) { #pull them off
    temp <- untangle.specials(Terms2, 'strata')
    strata2 <- strata(mf2[temp$vars], shortlabel=TRUE)
    strata2 <- factor(strata2, levels=levels(strata))
    if (any(is.na(strata2)))
        stop("New data set has strata levels not found in the original")
    # An expression like age:strata(sex) will have temp$vars= "strata(sex)"
    #  and temp$terms = integer(0).  This does not work as a subscript
    if (length(temp$terms) >0) Terms2 <- Terms2[-temp$terms]
}
else strata2 <- factor(rep(0, nrow(mf2)))

if (!robust) cluster <- NULL
if (individual) {
    if (missing(newdata)) 
        stop("The newdata argument must be present when individual=TRUE")
    if (!missid) {  #grab the id variable
        id2 <- model.extract(mf2, "id")
        if (is.null(id2)) stop("id=NULL is an invalid argument")
        }
    else id2 <- rep(1, nrow(mf2))
    
    x2 <- model.matrix(Terms2, mf2)[,-1, drop=FALSE]  #no intercept
    if (length(x2)==0) stop("Individual survival but no variables")

    offset2 <- model.offset(mf2)
    if (length(offset2) ==0) offset2 <- 0
 		
    y2 <- model.extract(mf2, 'response')
    if (attr(y2,'type') != type)
        stop("Survival type of newdata does not match the fitted model")
    if (attr(y2, "type") != "counting")
        stop("Individual=TRUE is only valid for counting process data")
    y2 <- y2[,1:2, drop=F]  #throw away status, it's never used
}
else if (missing(newdata)) {
    if (has.strata && strata.interaction)
        stop ("Models with strata by covariate interaction terms require newdata")
    offset2 <- 0
    if (length(object$means)) {
        x2 <- matrix(object$means, nrow=1, ncol=ncol(X))
    } else {
        # model with only an offset and no new data: very rare case 
        x2 <- matrix(0.0, nrow=1, ncol=1)   # make a dummy x2
    }
} else {
    offset2 <- model.offset(mf2)
    if (length(offset2) >0) offset2 <- offset2 
    else offset2 <- 0
    x2 <- model.matrix(Terms2, mf2)[,-1, drop=FALSE]  #no intercept
}
@ 

<<survfit.coxph-result>>=
if (individual) {
    result <- coxsurv.fit(ctype, stype, se.fit, varmat, cluster, 
                           Y, X, weights, risk, position, strata, oldid,
                           y2, x2, risk2, strata2, id2)
}
else {
    result <- coxsurv.fit(ctype, stype, se.fit, varmat, cluster, 
                           Y, X, weights, risk, position, strata, oldid,
                           y2, x2, risk2)
    if (has.strata && found.strata) {
        if (is.matrix(result$surv)) {
            <<newstrata-fixup>>
        }
    }
}
@ 

The final bit of work.  If the newdata arg contained strata then the
user should not get a matrix of survival curves containing
every newdata obs * strata combination, but rather a vector
of curves, each one with the appropriate strata.
It was faster to compute them all, however, than to use the individual=T
logic.  So now pick off the bits we want.
The names of the curves will be the rownames of the newdata arg,
if they exist.
<<newstrata-fixup>>=
nr <- nrow(result$surv)  #a vector if newdata had only 1 row
indx1 <- split(1:nr, rep(1:length(result$strata), result$strata))
rows <- indx1[as.numeric(strata2)]  #the rows for each curve

indx2 <- unlist(rows)  #index for time, n.risk, n.event, n.censor
indx3 <- as.integer(strata2) #index for n and strata

for(i in 2:length(rows)) rows[[i]] <- rows[[i]]+ (i-1)*nr #linear subscript
indx4 <- unlist(rows)   #index for surv and std.err
temp <- result$strata[indx3]
names(temp) <- row.names(mf2)
new <- list(n = result$n[indx3],
            time= result$time[indx2],
            n.risk= result$n.risk[indx2],
            n.event=result$n.event[indx2],
            n.censor=result$n.censor[indx2],
            strata = temp,
            surv= result$surv[indx4],
            cumhaz = result$cumhaz[indx4])
if (se.fit) new$std.err <- result$std.err[indx4]
result <- new
@ 

Finally, the last (somewhat boring) part of the code.  
First, if given the argument \code{censor=FALSE} we need to
remove all the time points from the output at which there
was only censoring activity.  This action is mostly for
backwards compatability with older releases that never
returned censoring times.
Second, add 
in the variance and the confidence intervals to the result.
The code is nearly identical to that in survfitKM.
<<survfit.coxph-finish>>=
if (!censor) {
    kfun <- function(x, keep){ if (is.matrix(x)) x[keep,,drop=F] 
                              else if (length(x)==length(keep)) x[keep]
                              else x}
    keep <- (result$n.event > 0)
    if (!is.null(result$strata)) {
        temp <- factor(rep(names(result$strata), result$strata),
                       levels=names(result$strata))
        result$strata <- c(table(temp[keep]))
        }
    result <- lapply(result, kfun, keep)
    }
result$logse = TRUE   # this will migrate further in

if (se.fit && conf.type != "none") {
    ci <- survfit_confint(result$surv, result$std.err, logse=result$logse,
                          conf.type, conf.int)
    result <- c(result, list(lower=ci$lower, upper=ci$upper, 
                             conf.type=conf.type, conf.int=conf.int))
}
if (!missing(start.time)) result$start.time <- start.time
result$call <- Call

# Rearrange to match the historical order of the structure
indx <- match('surv', names(result))
result <- c(result[1:indx], type=attr(Y, 'type'), result[-(1:indx)])
class(result) <- c('survfitcox', 'survfit')
survfit23(result)
@ 
